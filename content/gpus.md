---
title: "显卡推荐"
description: "AI模型适合用哪些显卡，今天就为大家推荐一下显卡"
type: "page"
date: 2024-01-01T00:00:00+00:00
---


> 你的废话太多了，我不想看

好吧。2024年最值得推荐的入门级AI算力卡：**RTX 2080ti 22G**(￥2600) 或者 **Tesla P40 24G**(￥1600)。

> 我是好学生，老师教我！

请往下看。

## 我该买什么显卡？

有朋友问，我想测试（玩）大语言/Stable Difussion这些AI模型，应该买神马显卡呢？

**答案很简单。从RTX4090开始考虑，买你能够负担的起的最贵的显卡。**

![Alt text](../images/GPU%E6%8E%A8%E8%8D%90/GPU%20price%202024-5.png)

好吧，这是一个不太负责的答案。

我来翻译一下你的问题：我想玩大模型，最低得上什么卡呢？

其实，大模型也分三六九等，如果你只是跑最低的一等，4G显存可以玩，爷爷传下来的1050ti也能上。

如果你手头恰好有一张N卡，我是说NVIDIA的显卡，恰好它的显存不小于4G，那么你可以尝试用它跑一跑体量较小的模型。

例如Stable Diffusion 1.5 或者Qwen 1.5(1.8B)这些比较小的模型。

如果它能够满足你尝鲜的需求，那么你就不必再额外破费购置显卡了。

## 到底是哪些显卡呢？

好吧，你喜欢看列表，下面这些显卡都是可以用的：

- H100 SXM（80 GB）
- H100 PCle（80 GB）
- RTX 4090（24 GB）
- A6000 Ada（48 GB）
- L40（48 GB）
- RTX 4080（16 GB）
- A100（40/80 GB）
- RTX 4070 Ti（12 GB）
- RTX 3090 Ti（24 GB）
- V100（32 GB）
- V100（16 GB）
- RTX3090（24 GB）
- RTX 3080（10 GB）
- RTX 3080 Ti（12 GB）
- A6000（48 GB）
- Titan RTX（24 GB）
- RTX 6000（24 GB）
- RTX 8000（48 GB）
- Titan V（12 GB）
- A40（48 GB）
- RTX 2080 Ti（11 GB）
- RTX 3070 Ti（8 GB）
- Titan Xp（12 GB）
- RTX 2080 Super（8 GB）
- GTX 1080 Ti（11 GB）
- Titan X Pascal（12 GB）
- RTX 2060 Super（8 GB）
- RTX 2070（8 GB）
- RTX 2070 Super（8 GB）
- RTX 2080（8 GB）
- RTX 3060 Ti（8 GB）
- RTX 3070（8 GB）
- GTX 1080（8 GB）
- RTX 3060（12 GB）
- RTX 3050（8 GB）
- GTX 1070（8 GB）
- GXT 1070 Ti（8 GB）
- GTX 1060（6 GB）

还有可怜的

- GTX 1050ti(4 GB)

找找看，你那落满灰尘的机箱里，有没有上面的某张显卡呢？

## 什么显卡性价比最高

很可惜，你一张上面的卡也没有。

> 那么，这时候，你就会问，我想买个性价比最高的。少花钱，多办事。

这是一个美好而又朴素的愿望。但是，很不现实。

少花钱，明显不能多办事。


> 这时候，你又问，我可以不在乎买二手卡，也可以不在乎速度，能跑起来就成！

好吧，你有点上道了。少花钱，不能多办事。但是可以专注办好其中一件事。那么我的建议就是：

**显存！显存！显存！**

因此，我只推荐两张卡：**RTX 2080ti 22G** 或者 **Tesla P40 24G**

RTX 2080ti 22G 是一张魔改卡，官方版本只出到了11G显存，后期通过修改BIOS和加焊芯片实现了22G显存。**市价大约在2700左右**。

Tesla P40 24G 是一张数据中心专用的计算卡，没有显示器接口，没有风扇，需要走核显或者亮机卡（低性能、便宜、带显示接口的显卡）才能实现显示信号输出。如果你用的是服务器，有相应的散热风道，那么插上就能用。如果你的是普通家用PC，还需要额外购买3D打印的散热风扇组件。**这张卡的价格大约在1700左右，散热组件的价格大约70**。

其他的卡就不推荐了。

## 笔记本怎么选？

> 这时候，你又问，如果我买笔记本，阁下又如何应对？

嗨，笔记本就别玩了呗。

这是玩笑。你如果考虑笔记本的话，ROG、外星人也有搭配4080显卡的本子，但是我想，如果你买的起，也不会纠结得到处看评测了。

实际上我的3050ti（4G）游戏本也是可以跑Stable Diffusion和LLM的。这种配置的二手游戏本大概3500左右可以买到。新本子的话，至少考虑4060以上显卡。七彩虹的一款4070游戏本价格也打到了6500左右，用来玩一下绘图、推理都没有大问题。

笔记本做模型微调？还是别做白日梦了。

## 得寸进尺的问题

> 这时候，你又问，大佬，捡垃圾怎么捡？

这里就没什么好推荐的了。P4（600左右），1080ti（1000左右），勉强能用吧。


> 最后，你又问，我的AMD显卡......摩尔线程......鲲鹏......Google TPU......

抱歉，AMD的PyTorch好像到现在都没影呢。你还是老老实实拿AMD卡玩游戏去吧。
抱歉，摩尔线程好像有PyTorch了，但是只能Linux跑，效率貌似不高，如果单纯为了做技术测试，你就为科学献身吧。
抱歉，我买不起鲲鹏，鲲鹏不是我等凡夫俗子能玩的，但是鲲鹏已经出了大模型训练、微调和推理的框架，都是企业级的应用，您还是联系华为的技术支持吧。
抱歉，Google我不熟，我只会用Colab。


## 参考文献

下面是两篇非常专业的GPU评测博文可以参考，但都是2023年的数据，有些后来新发售的显卡不在表中。

### Stable Diffusion Benchmarks: 45 Nvidia, AMD, and Intel GPUs Compared
### 稳定扩散基准测试：45个Nvidia、AMD和Intel GPU比较

Stable Diffusion和其他基于AI的图像生成工具，如Dall-E和Midjourney，是目前深度学习最受欢迎的应用。使用经过训练的网络来创建图像、视频和文本已经不仅仅是一种理论上的可能性，现在已经成为现实。虽然像ChatGPT这样更高级的工具可能需要安装大型服务器和大量硬件进行训练，但运行已经训练好的网络进行推理可以在PC上使用其显卡完成。消费者GPU使用稳定扩散进行AI推理的速度有多快？我们就是来调查这个的。

https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/

![Alt text](../images/GPU%E6%8E%A8%E8%8D%90/STABLE%20DIFFUSION%20512X512%20PERFORMANCE.png)


### Which GPU(s) to Get for Deep Learning: My Experience and Advice for Using GPUs in Deep Learning
### 为深度学习选择哪种GPU：我在深度学习中使用GPU的经验和建议

深度学习是一个对计算要求很高的领域，您对GPU的选择将从根本上决定您的深度学习体验。但是，如果你想购买一个新的GPU，什么功能是重要的？GPU RAM、核心、张量核心、缓存？如何做一个具有成本效益的选择？本文将深入探讨这些问题，解决常见的误解，给予您如何看待GPU的直观理解，并将为您提供建议，这将帮助您做出适合您的选择。

https://www.tomshardware.com/pc-components/gpus/stable-diffusion-benchmarks

![Alt text](../images/GPU%E6%8E%A8%E8%8D%90/GPU%20INFER%20RANKING.png)